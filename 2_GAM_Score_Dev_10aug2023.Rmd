---
title: "Score Development: GAM, AUROC, & LASSO"
---


```{r}

################################################################################
## A. GAM in Training Set 
## Initial variable selection and identification of ideal cutoff values
################################################################################

# Fit the GAM model per candidate predictor and plot

#candidate_predictor_1
fitted.model.1 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_1), bs="ps"), method="REML", 
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_1\n############################\n\n")
summary(fitted.model.1)
plot(fitted.model.1, shade=T, scale=0, xlab="candidate_predictor_1", ylab="f(candidate_predictor_1)") 

#candidate_predictor_2
fitted.model.2 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_2), bs="ps"), method="REML", 
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_2\n############################\n\n")
summary(fitted.model.2)
plot(fitted.model.2, shade=T, scale=0, xlab="candidate_predictor_2", ylab="f(candidate_predictor_2)") 

#candidate_predictor_3
fitted.model.3 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_2), bs="ps"), method="REML", 
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_3\n############################\n\n")
summary(fitted.model.3)
plot(fitted.model.3, shade=T, scale=0, xlab="candidate_predictor_3", ylab="f(candidate_predictor_3)") 

#candidate_predictor_4
fitted.model.4 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_4), bs="ps"), method="REML", 
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_4\n############################\n\n")
summary(fitted.model.4)
plot(fitted.model.4, shade=T, scale=0, xlab="candidate_predictor_4", ylab="f(candidate_predictor_4)") 

#candidate_predictor_5
fitted.model.5 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_5), bs="ps"),  
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_5\n############################\n\n")
summary(fitted.model.5)
plot(fitted.model.5, shade=T, scale=0, xlab="candidate_predictor_5", ylab="f(candidate_predictor_5)")

#candidate_predictor_6
fitted.model.6 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_6), bs="ps"),
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_6\n############################\n\n")
summary(fitted.model.6)
plot(fitted.model.6, shade=T, scale=0, xlab="candidate_predictor_6", ylab="f(candidate_predictor_6)")

#candidate_predictor_7
fitted.model.7 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_7), bs="ps"),
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_7\n############################\n\n")
summary(fitted.model.7)
plot(fitted.model.7, shade=T, scale=0,
     xlab="candidate_predictor_7", ylab="f(candidate_predictor_7)")

#candidate_predictor_8  
fitted.model.8 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_8), bs="ps"),
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_8\n############################\n\n")
summary(fitted.model.8)
plot(fitted.model.8, shade=T, scale=0, xlab="candidate_predictor_8", ylab="f(candidate_predictor_8)")

#candidate_predictor_9 
fitted.model.9 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_9), bs="ps"),
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_9\n############################\n\n")
summary(fitted.model.9)
plot(fitted.model.9, shade=T, scale=0, xlab="candidate_predictor_9", ylab="f(candidate_predictor_9)")

#candidate_predictor_10
fitted.model.10 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_10), bs="ps"),
                          family=binomial, data = course.train)
cat("\n\n############################\n## candidate_predictor_10\n############################\n\n")
summary(fitted.model.10)
plot(fitted.model.10, shade=T, scale=0, xlab="candidate_predictor_10", ylab="f(candidate_predictor_10)")


#proceed as above for additional candidate predictors

```


```{r}

####################################################
## B. Evaluate and determine cut-offs values 
## Compute AUC and AIC and compare AUCs
####################################################


#candidate_predictor_1 cut-off evaluation

#Code cutoff values in db, based on GAM in section A
cand_pred1_db<- course.train %>% 
  dplyr::select(candidate_predictor_1, outcome_variable) %>%
  mutate(pred1_cut4 = case_when(candidate_predictor_1<6 ~ 0, 
                             (candidate_predictor_1>=6 & candidate_predictor_1<9) ~ 1,
                              candidate_predictor_1>=9 & candidate_predictor_1<12 ~ 2, 
                             candidate_predictor_1>=12 ~ 3)) %>% 
  mutate(pred1_cut3 = case_when(candidate_predictor_1<6 ~ 0, 
                             (candidate_predictor_1 >=9 & candidate_predictor_1<12) ~ 1,
                              candidate_predictor_1>=12 ~ 2)) %>% 
  mutate(pred1_cut2 = case_when(candidate_predictor_1<9 ~ 0, 
                              candidate_predictor_1>=9 ~ 1)) 

#fit models based on above cutoff values
fit.cand_pred1.cut.2<-glm(outcome_variable~pred1_cut2,family=binomial, data=cand_pred1_db)
fit.cand_pred1.cut.3<-glm(outcome_variable~pred1_cut3,family=binomial, data=cand_pred1_db)
fit.cand_pred1.cut.4<-glm(outcome_variable~pred1_cut4,family=binomial, data=cand_pred1_db)

fitted.model.1 <- gam(as.numeric(outcome_variable)~s(as.numeric(candidate_predictor_1), bs="ps"), method="REML", 
                          family=binomial, data = ddy_db)

#calculate roc per model
roc.gam = roc(cand_pred1_db$outcome_variable ~ fitted.model.1$fitted.values)
roc.cand_pred1.cut2 = roc(cand_pred1_db$outcome_variable ~ fit.cand_pred1.cut.2$fitted.values)
roc.cand_pred1.cut3 = roc(cand_pred1_db$outcome_variable ~ fit.cand_pred1.cut.3$fitted.values)
roc.cand_pred1.cut4 = roc(cand_pred1_db$outcome_variable ~ fit.cand_pred1.cut.4$fitted.values)

#compare roc per model
roc.test(roc.cand_pred1.cut2,roc.gam)
roc.test(roc.cand_pred1.cut3,roc.gam)
roc.test(roc.cand_pred1.cut4,roc.gam)
roc.test(roc.cand_pred1.cut2,roc.cand_pred1.cut3)
roc.test(roc.cand_pred1.cut2,roc.cand_pred1.cut4)
roc.test(roc.cand_pred1.cut3,roc.cand_pred1.cut4)


#repeat for all candidate predictors identified in section A.

```

```{r}

#####################################################################################################################
## C. LASSO Regression
## Coefficient determination and Model Factor Selection
####################################################################################################################

#create the categorical predictor variables for lasso regression coefficient determination. 
#Cutoff values provided in this stage are dependent on the results in section B
course.train_binary_analysis<-course.train %>% 
  filter(!is.na(outcome_variable)) %>% 
    mutate(candidate_predictor_1_cut3 = case_when(candidate_predictor_1<2.0 ~ 0, 
                             (candidate_predictor_1 >=2.0 & candidate_predictor_1 < 3.0) ~ 1,
                              candidate_predictor_1 >= 3.0 & candidate_predictor_1<4.0 ~ 2, 
                              candidate_predictor_1>=4.0 ~ 3)) %>%
   mutate(candidate_predictor_2_cut3 = case_when(candidate_predictor_2 < 34 ~ 0, 
                             (candidate_predictor_2 >= 34 & candidate_predictor_2<40) ~ 1, 
                             candidate_predictor_2>=40 ~ 2)) %>%   
   mutate(candidate_predictor_3_cut3 = case_when(candidate_predictor_3<6 ~ 0, 
                             (candidate_predictor_3 >=6 & candidate_predictor_3<9) ~ 1,
                              candidate_predictor_3>=9 & candidate_predictor_3<12~2,
                             candidate_predictor_3>=12 ~ 3)) %>% 
    mutate(candidate_predictor_4_cut3 = case_when(candidate_predictor_3 < 34 ~ 0,
                              candidate_predictor_3>=34~ 1)) %>% 
  dplyr::select(outcome_variable, candidate_predictor_1_cut3, candidate_predictor_2_cut3, 
                candidate_predictor_3_cut3, candidate_predictor_4_cut3) 

# Prepare your data
x_train <- model.matrix(outcome_variable ~ ., data = course.train_binary_analysis)
y_train <- course.train_binary_analysis$outcome_variable

# Fit model with cross-validation (lasso for feature selection)
lasso_model <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 1)

# Determine the optimal lambda value
lasso_best_lambda <- lasso_model$lambda.min
lasso_best_lambda

# Fit the final model with the optimal lambda
lasso_final_model <- glmnet(x_train, y_train, family = "binomial", alpha = 1, lambda = lasso_best_lambda)

# Retrieve the coefficients
lasso_coefs <- coef(lasso_final_model)
lasso_coefs

```


```{r}

################################################################################
## D. Define the risk score
################################################################################

#create score based on feature selection & cutoff determinations made above
#Cutoff determination based on results from section B. Final feature selection based on results from section C
full_db <- full_db %>%
  mutate(risk_score = 0) %>%
  mutate(risk_score = ifelse(candidate_predictor_1>=2.0 & candidate_predictor_1<3.0, risk_score+2, risk_score)) %>%
  mutate(risk_score = ifelse(candidate_predictor_1>=3.0 & candidate_predictor_1<4.0, risk_score+4, risk_score)) %>%
  mutate(risk_score = ifelse(candidate_predictor_1>=4.0, risk_score+6, risk_score)) %>%
  mutate(risk_score = ifelse((candidate_predictor_2 >= 40 & candidate_predictor_2 < 50), risk_score+1, 
                        ifelse((candidate_predictor_2 >= 50), risk_score+2, 
                               risk_score))) %>%
  mutate(risk_score = ifelse((candidate_predictor_3 >= 7 & candidate_predictor_3 < 10), risk_score+1, risk_score
                    )) %>%
  mutate(risk_score = ifelse((candidate_predictor_3 >= 10 & candidate_predictor_3<12), risk_score+2, 
                        ifelse(candidate_predictor_3>=12, risk_score+3, risk_score)
                    )) %>%
  mutate(risk_score = ifelse(candidate_predictor_4>=34, risk_score+1, risk_score)) %>%
  mutate(risk_score_group4 = case_when(risk_score < 3 ~ "very low", 
                                 (risk_score>=3 & risk_score<8) ~ "low",
                                 risk_score>=8 & risk_score<10 ~ "medium",
                                 risk_score >=10 ~ "high")) %>%
  mutate(risk_score_group4 = factor(risk_score_group4, levels=c("very low", "low", "medium", "high")))


```



```{r}

############################################################################
# E. re-establish test and train, same groups as in first section of study
############################################################################

#re-apply previously established train-test split
course.train <- full_db[split, ]
course.test <- full_db[-split, ]

#report
table(full_db$risk_score)
table(full_db$risk_score_group4)


```


